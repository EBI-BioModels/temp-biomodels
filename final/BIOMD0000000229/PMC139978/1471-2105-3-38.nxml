<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Bioinformatics</journal-id><journal-title-group><journal-title>BMC Bioinformatics</journal-title></journal-title-group><issn pub-type="epub">1471-2105</issn><publisher><publisher-name>BioMed Central</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">12482327</article-id><article-id pub-id-type="pmc">139978</article-id><article-id pub-id-type="publisher-id">1471-2105-3-38</article-id><article-id pub-id-type="doi">10.1186/1471-2105-3-38</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research article</subject></subj-group></article-categories><title-group><article-title>Quantifying robustness of biochemical network models</article-title></title-group><contrib-group><contrib contrib-type="author" id="A1"><name><surname>Ma</surname><given-names>Lan</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>lma@jhu.edu</email></contrib><contrib contrib-type="author" corresp="yes" id="A2"><name><surname>Iglesias</surname><given-names>Pablo A</given-names></name><xref ref-type="aff" rid="I1">1</xref><email>pi@jhu.edu</email></contrib></contrib-group><aff id="I1"><label>1</label>Department of Electrical and Computer Engineering, The Johns Hopkins University, Baltimore, MD USA</aff><pub-date pub-type="collection"><year>2002</year></pub-date><pub-date pub-type="epub"><day>13</day><month>12</month><year>2002</year></pub-date><volume>3</volume><fpage>38</fpage><lpage>38</lpage><history><date date-type="received"><day>30</day><month>8</month><year>2002</year></date><date date-type="accepted"><day>13</day><month>12</month><year>2002</year></date></history><permissions><copyright-statement>Copyright &#x000a9;2002 Ma and Iglesias; licensee BioMed Central Ltd. This is an Open Access article: verbatim copying and redistribution of this article are permitted in all media for any purpose, provided this notice is preserved along with the article's original URL.</copyright-statement><copyright-year>2002</copyright-year><copyright-holder>Ma and Iglesias; licensee BioMed Central Ltd. This is an Open Access article: verbatim copying and redistribution of this article are permitted in all media for any purpose, provided this notice is preserved along with the article's original URL.</copyright-holder></permissions><self-uri xlink:href="http://www.biomedcentral.com/1471-2105/3/38"/><abstract><sec><title>Background</title><p>Robustness of mathematical models of biochemical networks is important for validation purposes and can be used as a means of selecting between different competing models. Tools for quantifying parametric robustness are needed.</p></sec><sec><title>Results</title><p>Two techniques for describing quantitatively the robustness of an oscillatory model were presented and contrasted. Single-parameter bifurcation analysis was used to evaluate the stability robustness of the limit cycle oscillation as well as the frequency and amplitude of oscillations. A tool from control engineering &#x02013; the structural singular value (SSV) &#x02013; was used to quantify robust stability of the limit cycle. Using SSV analysis, we find very poor robustness when the model's parameters are allowed to vary.</p></sec><sec><title>Conclusion</title><p>The results show the usefulness of incorporating SSV analysis to single parameter sensitivity analysis to quantify robustness.</p></sec></abstract></article-meta></front><body><sec><title>Background</title><p>Complex molecular networks mediate intracellular signalling events. These systems must operate reliably under vastly different environmental conditions that can cause large changes in the internal "parameters" of the system. The notion of robustness in biological systems has received considerable interest in the literature recently. By saying that a system is robust we imply that a particular function or characteristic of the system is preserved despite changes in the operating environment of the system. For example, by means of a computer model, Barkai and Leibler demonstrated that the adaptation mechanism found in the chemotactic signalling pathway in <italic>Escherichia coli </italic>is robust [<xref ref-type="bibr" rid="B1">1</xref>]. This was later confirmed experimentally [<xref ref-type="bibr" rid="B2">2</xref>]. A model of segment polarity network in <italic>Drosophila </italic>embryos was also found to be insensitive to variations in kinetic constants that govern its behaviour [<xref ref-type="bibr" rid="B3">3</xref>]. A similar approach was later used to show that a core neurogenic network in <italic>Drosophila </italic>successfully formed three test patterns across a wide range of parameter values [<xref ref-type="bibr" rid="B4">4</xref>] leading Meir <italic>et al. </italic>to propose that the ability to resist parameter fluctuations may be essential for gene network evolutionary flexibility.</p><p>Since the signalling pathways are robust, we should expect that mathematical models that attempt to explain these networks also be robust to parameter variations. This has long been appreciated. For example, Savageau, in [<xref ref-type="bibr" rid="B5">5</xref>], argues for parameter sensitivities as a means of evaluating the performance of biochemical systems. More recently, Morohashi <italic>et al. </italic>propose that robustness of a model to parameter variations be used as a criterion for determining plausibility between different models [<xref ref-type="bibr" rid="B6">6</xref>].</p><p>If we are to use robustness as a means of evaluating the quality of a model, we need objective measures of this robustness. One common technique is through parameter sensitivities. For simple systems, the sensitivity of a model of a network to individual parameters can be evaluated analytically [<xref ref-type="bibr" rid="B5">5</xref>,<xref ref-type="bibr" rid="B7">7</xref>]. For more complex networks, it can be determined computationally by repeated simulation varying one parameter while holding all others fixed; [<xref ref-type="bibr" rid="B3">3</xref>,<xref ref-type="bibr" rid="B8">8</xref>]. This single parameter sensitivity is also useful for testing robustness of a biochemical network in the laboratory. For example, it is by systematically varying the concentration of the chemotaxis-network proteins in <italic>E. coli </italic>and determining their effect &#x02013; or lack thereof &#x02013; on the precision of adaptation that Alon <italic>et al. </italic>determined the robustness of this system [<xref ref-type="bibr" rid="B2">2</xref>].</p><p>Single parameter insensitivity is necessary for a robust network, but may not be sufficient owing to interactions between several parameters. This is particularly true <italic>in vivo </italic>where many different system parameters will differ from their "nominal" values simultaneously. The tools available for quantifying this multiparametric uncertainty are more limited. Systematic changes of many parameters at a time suffer from an exponential increase in the number of parameters that need to be changed. This "curse of dimensionality" makes varying more than a handful of parameters simultaneously to assess parameter sensitivity impractical. For this reason, sensitivities for several parameters have been traditionally addressed through computer simulations based on Monte Carlo methods [<xref ref-type="bibr" rid="B9">9</xref>] &#x02013; randomly varying all parameter in the model [<xref ref-type="bibr" rid="B1">1</xref>,<xref ref-type="bibr" rid="B4">4</xref>]. However, because of their reliance on random methods, Monte Carlo methods cannot <italic>guarantee </italic>robustness. In this paper we suggest an alternative method, originally developed for use in analysing robust stability in man-made automatic control systems.</p><p>The need for robust systems has been one of the primary concerns of control engineering. In fact, one of the earliest motivations for the study of feedback control systems was the need to create robust telephone networks out of the highly variable vacuum tubes of the day. More recently, powerful tools for analysing the robustness of networks have emerged. In this paper we propose that one of these computational tools, known in control theory as the <italic>structural singular value </italic>(SSV) is of particular interest for biological networks [<xref ref-type="bibr" rid="B10">10</xref>]. We do this by contrasting single and multi-parameter sensitivities of a model of an oscillating biochemical network. We describe this model next.</p><sec><title>Model of an oscillating biochemical network</title><p>In [<xref ref-type="bibr" rid="B8">8</xref>], Laub and Loomis propose a model of the molecular network underlying adenosine 3',5'-cyclic monophosphate (cAMP) oscillations observed in fields of chemotactic <italic>Dictyostelium discoideum </italic>cells. The model, based on the network depicted in Fig. <xref ref-type="fig" rid="F1">1</xref>, induces the spontaneous oscillations in cAMP observed during the early development of <italic>D. discoideum.</italic></p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Laub and Loomis model. </bold>In their model of the aggregation network, pulses of cAMP are produced when adenlylate cyclase (ACA) is activated after the binding of extracellular cAMP to the surface receptor CAR1. When cAMP accumulates internally, it activates the protein kinase PKA. Ligand-bound CAR1 also activates the MAP kinase ERK2. ERK2 is then inactivated by PKA and no longer inhibits the cAMP phosphodiesterase REG A. A protein phosphatase activates REG A such that REG A can hydrolyse internal cAMP. When REG A hydrolyses the internal cAMP, PKA activity is inhibited by its regulatory subunit, and the activities of both ACA and ERK2 go up. Secreted cAMP diffuses between cells before being degraded by the secreted phosphodiesterase PDE.</p></caption><graphic xlink:href="1471-2105-3-38-1"/></fig><p>In this model, changes in the enzymatic activities of these proteins are described by a system of seven non-linear differential equations:<inline-graphic xlink:href="1471-2105-3-38-i1.gif"/></p><p>where the state variable <italic>x </italic>= [<italic>x</italic><sub>1</sub>,...,<italic>x</italic><sub>7</sub>] represents the concentrations of the seven proteins: <italic>x</italic><sub>1 </sub>= [ACA], <italic>x</italic><sub>2 </sub>= [PKA], <italic>x</italic><sub>3 </sub>= [ERK2], <italic>x</italic><sub>4 </sub>= [REG A], <italic>x</italic><sub>5 </sub>= [Internal cAMP], <italic>x</italic><sub>6 </sub>= [External cAMP] and <italic>x</italic><sub>7 </sub>= [CAR1] and the fourteen different <italic>k</italic><sub><italic>i </italic></sub>represent system parameter values. It was shown numerically in [<xref ref-type="bibr" rid="B8">8</xref>] that spontaneous oscillations appear at the nominal parameter values found in Table <xref ref-type="table" rid="T1">1</xref>. Note that because there are typographical errors in the original paper, the values being used here for the nominal parameters were obtained directly from the authors of [<xref ref-type="bibr" rid="B8">8</xref>].</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Parameter values For each parameter, <italic>k</italic><sub><italic>i </italic></sub>denotes the nominal value and the units involved.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center">Parameter</th><th align="center">Units</th><th align="center">Nominal Value</th><th align="center"><underline><italic>k</italic></underline><sub><italic>i</italic></sub></th><th align="center"><inline-graphic xlink:href="1471-2105-3-38-i2.gif"/><sub><italic>i</italic></sub></th><th align="center">DOR</th></tr></thead><tbody><tr><td align="center"><italic>k</italic><sub>1</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">2.0</td><td align="center">0.77</td><td align="center">55.74</td><td align="center">0.615</td></tr><tr><td align="center"><italic>k</italic><sub>2</sub><break/></td><td align="center">Mol<sup>-1</sup>min<sup>-1</sup></td><td align="center">0.9</td><td align="center">0.70</td><td align="center">3.59</td><td align="center">0.222</td></tr><tr><td align="center"><italic>k</italic><sub>3</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">2.5</td><td align="center">0.75</td><td align="center">16.91</td><td align="center">0.700</td></tr><tr><td align="center"><italic>k</italic><sub>4</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">1.5</td><td align="center">0</td><td align="center">1.82</td><td align="center">0.176</td></tr><tr><td align="center"><italic>k</italic><sub>5</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">0.6</td><td align="center">0.28</td><td align="center">5.15</td><td align="center">0.533</td></tr><tr><td align="center"><italic>k</italic><sub>6</sub><break/></td><td align="center">Mol<sup>-1</sup>min<sup>-1</sup></td><td align="center">0.8</td><td align="center">0.24</td><td align="center">2.06</td><td align="center">0.612</td></tr><tr><td align="center"><italic>k</italic><sub>7</sub><break/></td><td align="center">Mol<sup>-1</sup>min<sup>-1</sup></td><td align="center">1.0</td><td align="center">0</td><td align="center">3.10</td><td align="center">0.677</td></tr><tr><td align="center"><italic>k</italic><sub>8</sub></td><td align="center">Mol<sup>-1</sup>min<sup>-1</sup></td><td align="center">1.3</td><td align="center">0.19</td><td align="center">4.34</td><td align="center">0.700</td></tr><tr><td align="center"><italic>k</italic><sub>9</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">0.3</td><td align="center">0.09</td><td align="center">2.03</td><td align="center">0.700</td></tr><tr><td align="center"><italic>k</italic><sub>10</sub><break/></td><td align="center">Mol<sup>-1</sup>min<sup>-1</sup></td><td align="center">0.8</td><td align="center">0</td><td align="center">1.24</td><td align="center">0.350</td></tr><tr><td align="center"><italic>k</italic><sub>11</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">0.7</td><td align="center">0.33</td><td align="center">6.01</td><td align="center">0.529</td></tr><tr><td align="center"><italic>k</italic><sub>12</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">4.9</td><td align="center">2.80</td><td align="center">14.13</td><td align="center">0.429</td></tr><tr><td align="center"><italic>k</italic><sub>13</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">23.0</td><td align="center">9.36</td><td align="center">171.57</td><td align="center">0.593</td></tr><tr><td align="center"><italic>k</italic><sub>14</sub><break/></td><td align="center">min<sup>-1</sup></td><td align="center">4.5</td><td align="center">0.79</td><td align="center">5.80</td><td align="center">0.224</td></tr></tbody></table><table-wrap-foot><p>The values of <underline><italic>k</italic></underline><sub><italic>i </italic></sub>and <inline-graphic xlink:href="1471-2105-3-38-i2.gif"/><sub><italic>i </italic></sub>are the lower and upper limits in the interval in which stable limit cycles occur while that parameter is varied. The corresponding degree-of-robustness measure (DOR) is also given.</p></table-wrap-foot></table-wrap><p>This particular model is primarily concerned with describing self-sustaining oscillations in the biochemical system. From Fig. <xref ref-type="fig" rid="F2">2</xref>, it is clear that at the nominal parameter values of the model, this is achieved. We seek to determine whether the system is robust &#x02013; that is, if we change these kinetic parameters, will the systems oscillatory behaviour persist? We next present two possible means, based on whether parameters are changed one at a time or in groups.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Oscillations at nominal parameter values. </bold>Plot of the concentration of each of the seven variables as a function of time. This figure shows the oscillatory behaviour seen in all the variables.</p></caption><graphic xlink:href="1471-2105-3-38-2"/></fig></sec></sec><sec sec-type="methods"><title>Methods</title><sec><title>Single parameter robustness: Bifurcation analysis</title><p>Self-sustained oscillations such as those being modelled here appear as stable limit cycles in trajectory of the underlying dynamical system [<xref ref-type="bibr" rid="B11">11</xref>]. The existence and stability of these limit cycles may change under parametric perturbations. Whenever a stable periodic solution loses stability as we vary the underlying parameters of the system and this solution transitions to another qualitative solution &#x02013; for example, a steady-state equilibrium &#x02013; we say that the system undergoes a <italic>Hopf bifurcation. </italic>It is therefore possible to use bifurcation theory as a means of quantifying the robustness of this oscillatory network model [<xref ref-type="bibr" rid="B12">12</xref>,<xref ref-type="bibr" rid="B13">13</xref>].</p><p>Using the bifurcation analysis package AUTO [<xref ref-type="bibr" rid="B14">14</xref>], it is possible to produce one-parameter bifurcation diagrams for each of the model parameters <italic>k</italic><sub><italic>i</italic></sub>. These diagrams illustrate the steady-state behaviour of the systems as the parameter values are changed. Suppose that Hopf bifurcations occur at <underline><italic>k</italic></underline><sub><italic>i </italic></sub>and <inline-graphic xlink:href="1471-2105-3-38-i2.gif"/><sub><italic>i </italic></sub>so that (stable) limit cycles occur for the range (<underline><italic>k</italic><sub><italic>i</italic></sub></underline>, <inline-graphic xlink:href="1471-2105-3-38-i2.gif"/><sub><italic>i</italic></sub>). Both the size of this interval as well as the proximity of the nominal parameter value to either boundary are measures of the robustness of the system. To compare the robustness of the system to the different parameters, we can define a series of parametric robustness measures. We define the <italic>degree of robustness </italic>(DOR) for each parameter <italic>k</italic><sub><italic>i </italic></sub>as:<inline-graphic xlink:href="1471-2105-3-38-i3.gif"/></p><p>It is straightforward to see that this value is always between zero and one. The former indicates extreme parameter sensitivity whereas the latter implies large insensitivity.</p><p>Bifurcation diagrams provide an excellent means of determining the robustness of systems to single parameter perturbations. We next describe a method for analysing and quantifying robustness to simultaneous changes in several parameters.</p></sec><sec><title>Multiparametric robustness: Structural singular values</title><p>As in biological networks, engineering systems must also be robust to variations in the parametric values of its components. Developing tools for the analysis and design of robust automatic control systems has been an area of active research during the last two decades in control theory. One of the most powerful frameworks for measuring robustness known is the <italic>structural singular value </italic>(SSV) which is due to Doyle and co-workers [<xref ref-type="bibr" rid="B15">15</xref>].</p><p>We first define and illustrate the use of the SSV to quantify robustness by means of a simple example. Suppose that a system is described by the first-order differential equation</p><p><inline-graphic xlink:href="1471-2105-3-38-i4.gif"/> = <italic>ax</italic></p><p>where the constant parameter <italic>a </italic>is uncertain, but is assumed to lie in the region <italic>a </italic>&#x02208; (<underline><italic>a</italic></underline>, <inline-graphic xlink:href="1471-2105-3-38-i5.gif"/>).</p><p>We would like to know when this system is <italic>robustly </italic>stable; that is, it is stable for all possible parameters. The differential equation can be rewritten as</p><p><inline-graphic xlink:href="1471-2105-3-38-i4.gif"/> = <italic>a</italic><sub>0</sub><italic>x </italic>+ <italic>b</italic><sub>0</sub><italic>v </italic>&#x000a0;&#x000a0;&#x000a0; (1)</p><p>where <italic>a</italic><sub>0 </sub>= (<inline-graphic xlink:href="1471-2105-3-38-i5.gif"/> + <underline><italic>a</italic></underline>)/2, <italic>b</italic><sub>0 </sub>= (<inline-graphic xlink:href="1471-2105-3-38-i5.gif"/> - <underline><italic>a</italic></underline>)/2, <italic>v </italic>= &#x003b4;<italic>x </italic>and &#x003b4; &#x02208; (-1,1). In Eqn. (1), the term <italic>a</italic><sub>0 </sub>represents the nominal system description. Clearly, for the system to be stable we need <italic>a</italic><sub>0 </sub>&#x0003c; 0. The variable &#x003b4; represents all possible uncertainty in the parameter of the system, whereas <italic>b</italic><sub>0 </sub>dictates the uncertainty's effect on the nominal model. We would like to maintain system stability no matter what the value of &#x003b4; happens to be. Note that the system can be redrawn in the form of a feedback loop as in Fig. <xref ref-type="fig" rid="F3">3A</xref>. From the small gain theorem [<xref ref-type="bibr" rid="B16">16</xref>], it is known that if the nominal system is stable (<italic>a</italic><sub>0 </sub>&#x0003c; 0), the uncertain system will remain so whenever the gain around the loop is less than one. That is, if we denote the system transfer function &#x02013; the ratio of Fourier transforms of output over input &#x02013; as<inline-graphic xlink:href="1471-2105-3-38-i6.gif"/></p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Structured singular value analysis framework. </bold>In (A) we show how the uncertain system from Eqn. (1) can be represented in a feedback interconnection involving a nominal system and the uncertainty &#x003b4;. The signal <italic>v </italic>= &#x003b4;<italic>x </italic>provides the feedback. (B) For general systems, uncertainty can also be expressed as a feedback connection of a nominal model and an uncertainty matrix &#x00394;. In this case, the signals <italic>u </italic>and <italic>y </italic>provide the interconnections. The transfer function <italic>G</italic>(&#x003c9;) = <italic>C</italic><sub>0 </sub>(<italic>i&#x003c9;I </italic>- <italic>A</italic><sub>0</sub>)<sup>-1 </sup><italic>B</italic><sub>0 </sub>+ <italic>D</italic><sub>0</sub>.</p></caption><graphic xlink:href="1471-2105-3-38-3"/></fig><p>(here <italic>i </italic>refers to the complex number <inline-graphic xlink:href="1471-2105-3-38-i7.gif"/> and &#x003c9; is the angular frequency) then the system is stable provided that 1 - <italic>G</italic>(&#x003c9;)&#x003b4; &#x02260; 0, for all frequencies &#x003c9;. Equivalently, the amount of uncertainty that the system can tolerate is given by<inline-graphic xlink:href="1471-2105-3-38-i8.gif"/></p><p>Thus, the function &#x003bc; = |<italic>G</italic>(&#x003c9;)| serves as a (frequency-dependent) measure of the amount of parameter uncertainty that the system can tolerate. In particular, if the size of the uncertainty &#x003b4; is always less than 1/&#x003bc;, then the system is robustly stable. In this example, since |&#x003b4;| &#x0003c; 1, robust stability is guaranteed whenever <italic>b</italic><sub>0 </sub>&#x0003c; |<italic>a</italic><sub>0</sub>|.</p><p>It is clear that this simple model does not require extensive analytic tools to determine robust stability. Nevertheless, the procedure above can be generalized to systems of the form<inline-graphic xlink:href="1471-2105-3-38-i9.gif"/></p><p>where <italic>A</italic><sub>0</sub>, is a matrix describing the nominal model, <italic>B</italic><sub>0</sub>, <italic>C</italic><sub>0</sub>, and <italic>D</italic><sub>0 </sub>are matrices of appropriate dimensions describing the way that the uncertain parameters affect the nominal model. This uncertainty is modelled by the matrix &#x00394; which is unknown, but is assumed to belong to the set <inline-graphic xlink:href="1471-2105-3-38-i10.gif"/>[<xref ref-type="bibr" rid="B10">10</xref>]. The signal <italic>u </italic>= &#x00394;<italic>y </italic>completes the feedback loop as shown in Fig. <xref ref-type="fig" rid="F3">3B</xref>. For these systems, the appropriate measure of robustness is now given by the structural singular value (SSV)</p><p>&#x003bc;<sub>&#x00394; </sub>(<italic>G</italic>) = (min{||&#x00394;||:&#x00394; &#x02208; <inline-graphic xlink:href="1471-2105-3-38-i10.gif"/>, det(<italic>I </italic>- <italic>G</italic>&#x00394;) &#x02260; 0})<sup>-1 </sup>&#x000a0;&#x000a0;&#x000a0; (3)</p><p>Here, <italic>G</italic>(&#x003c9;) = <italic>C</italic><sub>0 </sub>(<italic>i&#x003c9;I </italic>- <italic>A</italic><sub>0</sub>)<sup>-1 </sup><italic>B</italic><sub>0 </sub>+ <italic>D</italic><sub>0 </sub>and <italic>I </italic>is the identity matrix of appropriate dimensions.</p><p>Since we are interested in the robustness of the oscillatory property of this system, it is natural to use the SSV to quantify the robust stability of the limit cycle. However, in order to use the SSV tool, the original perturbed system must be transformed into a framework consisting of a nominal linear time invariant (LTI) system interconnected with a perturbation matrix. For the case of an oscillatory non-linear model, this involves several steps, which we outline next.</p><sec><title>Determining the limit cycle: Harmonic balance method</title><p>The first step is to obtain a mathematical expression for the limit cycle oscillation. The harmonic balance method can be used [<xref ref-type="bibr" rid="B17">17</xref>]. The basic idea is to represent the limit cycle by a Fourier series with unknown coefficients (<italic>a</italic><sub><italic>n</italic>,<italic>i</italic></sub>, &#x003c6;<sub><italic>n</italic>,<italic>i</italic></sub>) and period <italic>T</italic>:<inline-graphic xlink:href="1471-2105-3-38-i11.gif"/></p><p>The non-linear differential equation can be used to set up a series of algebraic equations that the coefficients must satisfy. These equations can be solved using numerical packages such as Mathematica or Maple. Depending on the particular form of the limit cycle, a small finite number of coefficients can be used. We can denote this periodic solution as <italic>x</italic>*(<italic>t</italic>).</p></sec><sec><title>Linearization</title><p>The non-linear differential equation must now be linearized about this periodic orbit [<xref ref-type="bibr" rid="B17">17</xref>]. Writing the state vector <italic>x</italic>(<italic>t</italic>) as</p><p><italic>x</italic>(<italic>t</italic>) = <italic>x</italic>*(<italic>t</italic>) + <italic>x</italic><sub>&#x003b4; </sub>(<italic>t</italic>)</p><p>then the local behaviour of the non-linear system is governed by that of the linearized system:</p><p><inline-graphic xlink:href="1471-2105-3-38-i4.gif"/><sub>&#x003b4; </sub>(<italic>t</italic>) &#x02245; <italic>J </italic>(<italic>x</italic>*(<italic>t</italic>))<italic>x</italic><sub>&#x02248; </sub>(<italic>t</italic>)</p><p>where <italic>J </italic>is the Jacobian matrix of the vector field <italic>f</italic>. Note that since the linearization is performed about a periodic orbit, the linear system is periodic.</p></sec><sec><title>Restructuring into nominal/uncertainty systems</title><p>The Jacobian matrix includes all uncertain parameters. At this point we need to separate the system into a nominal model and a feedback interconnection that involves all parametric uncertainty. We first write each parameter as<inline-graphic xlink:href="1471-2105-3-38-i12.gif"/></p><p>where <italic>k</italic><sub><italic>i </italic></sub>is the nominal value and &#x003b4;<sub><italic>i </italic></sub>is the relative amount of perturbation in the <italic>i</italic><sup>th </sup>parameter. We now separate the Jacobian matrix as</p><p><italic>J </italic>(<italic>x</italic>*(<italic>t</italic>)) = <italic>A</italic><sub>0 </sub>(<italic>t</italic>) + <italic>B</italic><sub>0 </sub>(<italic>t</italic>) &#x00394; <italic>C</italic><sub>0 </sub>(<italic>t</italic>) &#x000a0;&#x000a0;&#x000a0; (4)</p><p>where <italic>A</italic><sub>0</sub>(<italic>t</italic>) is the Jacobian matrix with all parameters at their nominal value, and &#x00394; is a diagonal matrix containing all the uncertainties &#x003b4;<sub><italic>i</italic></sub>. Let <italic>y</italic>(<italic>t</italic>) = <italic>C</italic><sub>0</sub>(<italic>t</italic>) <italic>x</italic><sub>&#x003b4;</sub>(<italic>t</italic>) and <italic>u</italic>(<italic>t</italic>) = &#x00394;<italic>y</italic>(<italic>t</italic>), the system is now of the form of Eqn. (2) (with <italic>x</italic>(<italic>t</italic>) replaced by <italic>x</italic><sub>&#x003b4;</sub>(<italic>t</italic>)).</p></sec><sec><title>Discretization</title><p>The system can be discretized by sampling the state and output with sampling period <italic>h </italic>= <italic>T/n</italic>, where <italic>n </italic>is a positive integer and assuming that the inputs are piecewise constant; this is also a standard technique in control engineering [<xref ref-type="bibr" rid="B18">18</xref>]. In particular, a linear continuous-time system governed by Eqn. (2) gives rise to the discrete-time, linear system</p><p>&#x003be; (<italic>k </italic>+ 1) = <italic>A</italic><sub><italic>d </italic></sub>(<italic>k</italic>) &#x003be;(<italic>k</italic>) + <italic>B</italic><sub><italic>d </italic></sub>(<italic>k</italic>) <italic>v</italic>(<italic>k</italic>)</p><p>&#x003b7; (<italic>k</italic>) = <italic>C</italic><sub><italic>d </italic></sub>(<italic>k</italic>) &#x003be;(<italic>k</italic>)</p><p>where <italic>A</italic><sub><italic>d </italic></sub>(<italic>k</italic>) = &#x003a6; (<italic>kh </italic>+ <italic>h</italic>,<italic>kh</italic>), <italic>B</italic><sub><italic>d </italic></sub>(<italic>k</italic>) = <inline-graphic xlink:href="1471-2105-3-38-i13.gif"/> &#x003a6; (<italic>kh </italic>+ <italic>h</italic>, <italic>s</italic>) <italic>B</italic><sub>0 </sub>(<italic>s</italic>)<italic>ds</italic>, <italic>C</italic><sub><italic>d </italic></sub>(<italic>k</italic>) = <italic>C</italic><sub>0 </sub>(<italic>kh</italic>), and &#x003a6; (<italic>t</italic>, &#x003c4;) is the transition matrix of <italic>A</italic><sub>0 </sub>(<italic>t</italic>) [<xref ref-type="bibr" rid="B19">19</xref>]. The discretized signals are <italic>v</italic>(<italic>k</italic>) = <italic>u</italic>(<italic>kh</italic>), &#x003b7;(<italic>k</italic>) = <italic>y</italic>(<italic>kh</italic>), and &#x003be;(<italic>k</italic>) = <italic>x</italic>(<italic>kh</italic>). Periodicity of <italic>A</italic><sub><italic>d </italic></sub>and <italic>B</italic><sub><italic>d </italic></sub>is preserved due to the periodicity of the transition matrix. Moreover, it is not difficult to confirm that <italic>A</italic><sub><italic>d</italic></sub>, <italic>B</italic><sub><italic>d </italic></sub>and <italic>C</italic><sub><italic>d </italic></sub>are periodic with period <italic>n</italic>. The uncertainty matrix after discretization is now &#x00394;<sub><italic>d</italic></sub>. The discretization step is illustrated in Fig. <xref ref-type="fig" rid="F4">4A</xref>.</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Discretization using sampling. </bold>(A) This diagram illustrates the use of sampling (<italic>S</italic>) and first-order-hold (<italic>H</italic>) to discretize a continuous-time system. The sampling circuit's output is equal to the inputs at the sampling times. The first-order-hold circuits generate a piecewise-constant signal equal to the inputs. If we introduce two copies of these circuits into the loop of Fig. <xref ref-type="fig" rid="F3">3B</xref>, and group the subsystems as shown here, the effect is to generate a discrete-time nominal model <italic>G</italic><sub><italic>d </italic></sub>as well as a discrete-time uncertainty structure &#x00394;<sub><italic>d</italic></sub>. (B) The validity of this approximation will depend on the value of the sampling period, <italic>h </italic>= <italic>T/n</italic>, chosen. For the Laub &#x00026; Loomis model, the error for values of <italic>n </italic>greater than 8 is negligible. A comparison of the responses of the non-linear (solid blue), linearized continuous-time (dashed green) and discrete-time (dotted red) systems when <italic>n </italic>= 16 is shown, where we have plotted <italic>x</italic><sub>1 </sub>as a function of time for all responses. The latter two have been superimposed onto the nominal limit cycle (<italic>x</italic>*(<italic>t</italic>)) computed using the harmonic balance method.</p></caption><graphic xlink:href="1471-2105-3-38-4"/></fig></sec><sec><title>Lifting</title><p>The final step in preparing the system for SSV analysis is to transform the periodic, linearized system into an equivalent time-invariant one. The technique for this is known as <italic>lifting </italic>[<xref ref-type="bibr" rid="B18">18</xref>]. Rather than giving the general formulae, it is easier to illustrate the general principle with an example.</p><p>Suppose that a discrete-time system with state variable &#x003be;, input <italic>v</italic>, and output &#x003b7; obeys the difference equation</p><p>&#x003be; (<italic>k </italic>+ 1) = <italic>a</italic>(<italic>k</italic>)&#x003be;(<italic>k</italic>) + <italic>b</italic>(<italic>k</italic>)<italic>v</italic>(<italic>k</italic>)</p><p>&#x003b7; (<italic>k</italic>) = <italic>c</italic>(<italic>k</italic>)&#x003be;(<italic>k</italic>)</p><p>where the time varying coefficients <italic>a</italic>(<italic>k</italic>), <italic>b</italic>(<italic>k</italic>) and <italic>c</italic>(<italic>k</italic>) are all periodic with period two. Calculating the state variable and output step-by-step leads to:<inline-graphic xlink:href="1471-2105-3-38-i14.gif"/></p><p>for any integer <italic>p</italic>. By defining "lifted" inputs and outputs<inline-graphic xlink:href="1471-2105-3-38-i15.gif"/></p><p>and considering the system state only at the even time points (<inline-graphic xlink:href="1471-2105-3-38-i16.gif"/>(<italic>p</italic>) = &#x003be;(2<italic>p</italic>)) we arrive at an equivalent time-invariant system.</p><p>The lifting technique has been illustrated above for a discrete-time system with period two; however, it can be applied to systems with arbitrary period &#x02013; though the corresponding formulae are considerably more complicated; see [<xref ref-type="bibr" rid="B18">18</xref>].</p></sec><sec><title>Computation of SSV</title><p>There is considerable literature in control theory on the computation of the SSV; see for example [<xref ref-type="bibr" rid="B20">20</xref>-<xref ref-type="bibr" rid="B22">22</xref>]. For general classes of uncertainty, computing &#x003bc;<sub>&#x00394; </sub>is known to be NP-hard [<xref ref-type="bibr" rid="B21">21</xref>]. Typically, given the feedback loop consisting of <italic>G </italic>and &#x00394; we compute upper and lower bounds for the SSV [<xref ref-type="bibr" rid="B15">15</xref>]. The lower bound is exactly equal to &#x003bc;<sub>&#x00394; </sub>[<xref ref-type="bibr" rid="B15">15</xref>]; unfortunately computing this lower bound involves a search over a non-convex set and therefore may converge to local optimums that are not global. In contrast, the upper bound can be rewritten in terms of a convex optimisation problem, so that a global minimum can be obtained. However, this upper bound is, in general not tight. A software package is commercially available that can compute &#x003bc;<sup><italic>upper </italic></sup>and uses a power algorithm to attempt to compute &#x003bc;<sup><italic>lower </italic></sup>[<xref ref-type="bibr" rid="B22">22</xref>].</p></sec></sec></sec><sec><title>Results</title><sec><title>Single parameter robustness</title><p>The robustness of Laub and Loomis's oscillatory model was first analysed by means of single-parameter bifurcation diagrams. Four typical diagrams are shown in Fig. <xref ref-type="fig" rid="F5">5</xref>. The activity of internal cAMP (<italic>x</italic><sub>5</sub>) is plotted as a function of the variation of each parameter. We use internal cAMP in the diagram as it is the element that is usually observed experimentally [<xref ref-type="bibr" rid="B23">23</xref>]. In each of the diagrams, there are three types of solutions: stable steady state, unstable steady state and limit cycle oscillations.</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Single parameter bifurcation diagrams. </bold>In these diagrams, obtained using AUTO [<xref ref-type="bibr" rid="B14">14</xref>], we plot the steady state activity of internal cAMP (<italic>x</italic><sub>5</sub>) as a function of four individual parameters (<italic>k</italic><sub>1</sub>, <italic>k</italic><sub>2</sub>, <italic>k</italic><sub>8 </sub>and <italic>k</italic><sub>10</sub>). In the diagrams, a stable steady state is represented by solid line; an unstable steady state is represented by dashed line; and a stable limit cycle is represented by a pair of solid circles with the upper indicating the maximum value of amplitude and the lower indicating the minimum value of amplitude. The transition from stable steady state to stable limit cycle or vice versa is called a Hopf bifurcation, which is indicated by a solid square in the plot. This type of bifurcation is caused by the appearance of a pair of pure imaginary eigenvalues of the Jacobian matrix of non-linear system. A star on the axis indicates the nominal value of each parameter.</p></caption><graphic xlink:href="1471-2105-3-38-5"/></fig><p>These diagrams illustrate that Hopf bifurcations occur for each parameter; that is, the oscillatory behaviour exists only in a limited range of parameters around the nominal value. For each of these parameters, the respective intervals and values for degree-of-robustness are found in Table <xref ref-type="table" rid="T1">1</xref>.</p></sec><sec><title>Structural singular value</title><p>From the numerical simulation (Fig. <xref ref-type="fig" rid="F2">2</xref>) of the non-linear model, we observed that the oscillatory curves did not deviate greatly from a simple harmonic oscillator plus a constant offset. Thus, to obtain an analytic expression for the periodic orbits we assume that the state variables are expanded into Fourier series containing only the fundamental and constant terms:<inline-graphic xlink:href="1471-2105-3-38-i17.gif"/></p><p>for each of the seven states. Since it is the relative phase shift between each state variable that is relevant, we assume that &#x003b8;<sub>1 </sub>= 0. The substitution of the Fourier series into the original equations leads to a series of real algebraic equations for the coefficients (not shown) whose solution was obtained using Mathematica. This leads us to obtain the corresponding periodic solutions where the values of <italic>A</italic><sub>0,<italic>i</italic></sub>, <italic>A</italic><sub>1,<italic>i </italic></sub>and &#x003b8;<sub><italic>i </italic></sub>are found in Table <xref ref-type="table" rid="T2">2</xref>. The period <italic>T </italic>is approximately 7.31 minutes. This analytic solution matches well with the numerical simulation except for an arbitrary phase shift, which does not affect the shape and location of the limit cycle in the phase space and can thereby be ignored (not shown).</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p>Fourier coefficients of the nominal periodic solution Values obtained for our Fourier series opproximation of the oscillatory behaviour.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center"><italic>i</italic></th><th align="center"><italic>A</italic><sub>0,<italic>i</italic></sub></th><th align="center"><italic>A</italic><sub>1,<italic>i</italic></sub></th><th align="center">&#x003b8;<sub>I </sub>(degrees)<break/></th></tr></thead><tbody><tr><td align="center">1</td><td align="center">2.431</td><td align="center">0.759</td><td align="center">0</td></tr><tr><td align="center">2</td><td align="center">1.631</td><td align="center">0.475</td><td align="center">-96.1</td></tr><tr><td align="center">3</td><td align="center">0.818</td><td align="center">0.248</td><td align="center">-3.1</td></tr><tr><td align="center">4</td><td align="center">0.967</td><td align="center">0.228</td><td align="center">138.0</td></tr><tr><td align="center">5</td><td align="center">0.978</td><td align="center">0.328</td><td align="center">-66.3</td></tr><tr><td align="center">6</td><td align="center">0.347</td><td align="center">0.107</td><td align="center">-10.0</td></tr><tr><td align="center">7</td><td align="center">1.775</td><td align="center">0.536</td><td align="center">-20.8</td></tr></tbody></table></table-wrap><p>Following our prescribed methods, we next linearized the system. The Jacobian matrix is obtained and was decomposed as in Eqn. (4) to obtain:<inline-graphic xlink:href="1471-2105-3-38-i18.gif"/></p><p>The matrix <italic>B</italic><sub>0 </sub>(<italic>t</italic>) = {<italic>B</italic><sub><italic>i</italic>,<italic>j</italic></sub>} where<inline-graphic xlink:href="1471-2105-3-38-i19.gif"/></p><p>Similarly, the matrix <italic>C</italic><sub>0 </sub>(<italic>t</italic>) = {<italic>C</italic><sub><italic>i</italic>,<italic>j</italic></sub>} where all coefficients are zero except for the following:<inline-graphic xlink:href="1471-2105-3-38-i20.gif"/></p><p>Finally, <italic>D</italic><sub>0 </sub>= 0 and the perturbation structure is given by</p><p>&#x00394; = diag {&#x003b4;<sub>1</sub>,&#x003b4;<sub>2</sub>,&#x003b4;<sub>2</sub>,&#x003b4;<sub>3</sub>,&#x003b4;<sub>4</sub>,&#x003b4;<sub>5</sub>,&#x003b4;<sub>6</sub>,&#x003b4;<sub>6</sub>,&#x003b4;<sub>8</sub>,&#x003b4;<sub>8</sub>,&#x003b4;<sub>9</sub>,&#x003b4;<sub>10</sub>,&#x003b4;<sub>10</sub>,&#x003b4;<sub>11</sub>,&#x003b4;<sub>12</sub>,&#x003b4;<sub>13</sub>,&#x003b4;<sub>14</sub>}</p><p>Note that since the nominal trajectory is periodic, the matrix functions in the nominal description are also periodic. Note also that in the uncertainty matrix, &#x00394;, some uncertainties are repeated (&#x003b4;<sub>2</sub>,&#x003b4;<sub>6</sub>,&#x003b4;<sub>8 </sub>and &#x003b4;<sub>10</sub>) while &#x003b4;<sub>7 </sub>is missing.</p><p>The system was then discretized and lifted following the procedure outlined above. A comparison of the system response for each of the approximations at the nominal parameter values is given in Fig. <xref ref-type="fig" rid="F4">4B</xref>.</p><p>For the sampling time we tried various values of <italic>n </italic>but found negligible differences for values above eight. Finally, we computed the bounds on the SSV. Once again, we found that the values of these two bounds were not affected much by the sampling frequency provided that <italic>n </italic>is greater than eight. The upper bound was successfully computed using [<xref ref-type="bibr" rid="B22">22</xref>]. The maximum over all frequencies is approximately 12.06. However, the high dimension of system causes convergence problem during the computation of &#x003bc;<sup><italic>lower </italic></sup>using this package. To obtain an acceptable lower bound, we calculate the spectral radius at each frequency. This gives us a lower bound for &#x003bc;<sup><italic>lower</italic></sup>. The plot of the bounds for the SSV when <italic>n </italic>= 16 is shown in Fig. <xref ref-type="fig" rid="F6">6</xref>. We can use &#x003bc;<sup><italic>lower </italic></sup>to obtain a conservative region for robust stability. The highest value over all frequencies for &#x003bc;<sup><italic>lower </italic></sup>is approximately 2.636.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Structured singular value bounds. </bold>Shown are the lower (dashed) and upper (solid) bounds for the structural singular value as a function of the frequency. Since we are interested in the largest value of &#x003bc; over all frequencies, we find that the maximum value of &#x003bc; is between 2.636 and 12.06.</p></caption><graphic xlink:href="1471-2105-3-38-6"/></fig></sec></sec><sec><title>Discussion</title><p>Recent years has seen an appreciation that key cellular properties are robust to variations in individual parameter values. Based on the topology of many of these networks, this should not be surprising. Feedback &#x02013; both negative and positive &#x02013; control systems are ubiquitous in most biological networks [<xref ref-type="bibr" rid="B24">24</xref>] and one of the reasons for using feedback is that it reduces sensitivity of a system's behaviour to its parameter values.</p><p>In modelling biological networks, it is important that this robustness also be in evidence. The particular behaviour being characterized by the model should not rely on precise values of the model's parameters &#x02013; for example, reaction rate constants or protein concentrations. In particular, a precise measurement of these constants is difficult whereas protein concentrations will vary from one cell to another or throughout the lifetime of any individual. Deviations from the nominal model parameter values should not result in a loss of the network's performance; thus, parameter sensitivity can be used to validate mathematical models of biochemical system. That is, the more insensitive the system response is to the accuracy of the parameter, the more faith we should have in the model [<xref ref-type="bibr" rid="B25">25</xref>].</p><p>In looking at certain classes of behaviour, where qualitative changes in the stability of the system are possible, bifurcation diagrams provide an elegant means of evaluating robustness. For example, in evaluating the robustness of the model of Laub and Loomis, of primary importance is determining whether the oscillatory behaviour will persist if the parameter values are altered. This qualitative difference in performance &#x02013; from limit cycle oscillations to constant steady states &#x02013; can be quantified and compared across parameters or from one model to another. Once the robustness of the oscillatory behaviour is established, further investigations of the robustness of some of the oscillatory features, for example frequency and amplitude can further be evaluated.</p><p>From the bifurcation diagrams obtained for each of the fourteen parameters, we know that oscillations exist only in a limited range around the nominal value. We find the system to be quite sensitive to variations in <italic>k</italic><sub>2</sub>, <italic>k</italic><sub>4</sub>, <italic>k</italic><sub>10 </sub>and <italic>k</italic><sub>14 </sub>and mostly insensitive to the others. Single-parameter bifurcation analysis also shows that the amplitude of the oscillation is greatly affected by the variation of 9 parameters (<italic>k</italic><sub>1</sub>, <italic>k</italic><sub>2</sub>, <italic>k</italic><sub>4</sub>, <italic>k</italic><sub>6</sub>, <italic>k</italic><sub>7</sub>, <italic>k</italic><sub>10</sub>, <italic>k</italic><sub>11</sub>, <italic>k</italic><sub>12</sub>, and <italic>k</italic><sub>14</sub>).</p><p>Based on the SSV stability to interpret multiple parameter sensitivity, we can conclude that robust stability of the periodic orbits will be maintained, provided that<inline-graphic xlink:href="1471-2105-3-38-i21.gif"/></p><p>Since the uncertainty matrix consists only of diagonal entries, this bound applies to each of the individual parameters. Thus, we can guarantee that the system will be robustly stable provided that no single parameter differs more than 8.3% from its nominal value.</p><p>In our analysis we found a large gap between &#x003bc;<sup><italic>upper </italic></sup>and our lower bound for &#x003bc;. As we later show, for this system the upper bound is fairly tight, as we are able to obtain a destabilizing perturbation of size 9%. For general biological models, a robustness measure based on the upper bound &#x003bc;<sup><italic>upper </italic></sup>may also be more appropriate. Robustness bounds for systems in which arbitrarily slowly-time-varying parameter values are allowed are known [<xref ref-type="bibr" rid="B26">26</xref>]. For these systems it has been shown that the bounds converge as the time-variations approach zero to the upper bound &#x003bc;<sup><italic>upper </italic></sup>[<xref ref-type="bibr" rid="B26">26</xref>]. Since many of the parameters in models of biochemical networks represent features that will vary over time, such as enzyme concentrations, this number may therefore be more indicative of the model's true robustness.</p><p>The ability to consider the effect of time-variations on the robustness of the system is one great advantage of the SSV over other methodologies. One drawback of the SSV approach compared to the bifurcation theory is that it does not provide the precise combination of parameters that destabilizes the system &#x02013; only its size. Also, since the upper bound is only sufficient to guarantee robustness, this number may, in general, give an overly conservative notion of robustness.</p><p>It must be emphasized that the SSV approach denoted here is based on the linearized model of the system. For some classes of systems this linearization may not be possible &#x02013; in this case, the linear SSV approach documented here will not be applicable. However, for most models used to describe biochemical reactions, this should not be a problem.</p><p>Because we are concentrating exclusively on the local stability of the linearized model, important parameters of the oscillatory behaviour such as robustness of the frequency and amplitudes of oscillation are not evaluated. Also, the effect of parameter variations on the equilibrium orbit are omitted. In particular, varying the kinetic parameters will change the behaviour of the system in two different ways: the equilibrium periodic orbit will change and the stability of deviations about this orbit will also change. The SSV allows one to quantify the robustness of the second of these two effects. It does not say anything directly regarding the effect of parameter variations on the equilibrium periodic orbit. One way of bounding the effect of these parameter changes is to write the original differential equation as</p><p><inline-graphic xlink:href="1471-2105-3-38-i4.gif"/>(<italic>t</italic>) = <italic>f</italic>(<italic>x</italic>,<italic>k</italic>)</p><p>where <italic>k </italic>= <italic>k</italic><sub>0 </sub>+ &#x003b4; is the set of kinetic parameters with nominal values <italic>k</italic><sub>0</sub>. If the nominal periodic orbit (when &#x003b4; = 0) is given by</p><p><italic>x</italic>*(<italic>t</italic>) = <italic>x</italic>(<italic>t</italic>) - <italic>x</italic><sub>&#x003b4; </sub>(<italic>t</italic>)</p><p>then, linearizing about this orbit yields</p><p><inline-graphic xlink:href="1471-2105-3-38-i4.gif"/><sub>&#x003b4;</sub>(<italic>t</italic>) = <italic>A</italic>(<italic>t</italic>)<italic>x</italic><sub>&#x003b4; </sub>(<italic>t</italic>) + <italic>v</italic></p><p>where <inline-graphic xlink:href="1471-2105-3-38-i22.gif"/> &#x003b4; is a constant vector that includes the effect of this parametric uncertainty. Thus, the system can be considered as being perturbed by a constant input signal <italic>v</italic>. Provided that the homogeneous system is exponentially stable (and this is guaranteed by the existence of a stable limit cycle) and that <italic>v </italic>is not "too large", the perturbed system's state will remain in a neighbourhood of the origin if the <italic>f</italic>(<italic>x</italic>,<italic>p</italic>) in the original equation is reasonably well behaved in <italic>k</italic>. Detailed bounds and conditions on <italic>f </italic>are given in Theorem 5.1 of [<xref ref-type="bibr" rid="B17">17</xref>], though it should be emphasized that these bounds tend to be overly conservative in practice.</p><p>To illustrate the local nature of the SSV analysis for this system, we perturbed the system parameters by varying amounts. The particular parameters were either increased or decreased so as to bring them closer to the Hopf bifurcation. For example, the nominal value of <italic>k</italic><sub>1 </sub>is closer to <underline><italic>k</italic></underline><sub>1 </sub>than to <inline-graphic xlink:href="1471-2105-3-38-i2.gif"/><sub>1 </sub>so that we reduced <italic>k</italic><sub>1 </sub>whereas <italic>k</italic><sub>4 </sub>is closer to <inline-graphic xlink:href="1471-2105-3-38-i2.gif"/><sub>4 </sub>than to <underline><italic>k</italic></underline><sub>4 </sub>so we increased <italic>k</italic><sub>4</sub>. In Fig. <xref ref-type="fig" rid="F7">7</xref> we show the response of these systems to changes of 7% and 9% both for the linearized system &#x02013; where the linearized response has been superimposed on the nominal limit cycle (Fig. <xref ref-type="fig" rid="F7">7A</xref>) and the original non-linear system (Fig. <xref ref-type="fig" rid="F7">7B</xref>). For the smaller value, the linearized response is stable and we see that, after a transient, the response settles to the nominal limit cycle. We also see this same behaviour in the response of the non-linear system with this level of parameter perturbation. For a 9% change in the parameters, however, the linearized system is unstable. We see this as a deviation from the nominal limit cycle. In the non-linear system's response, this translates into an end to the stable limit cycle. The response does not "blow up" but instead settles into a fixed point.</p><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>Comparison of linearized and non-linear responses for varying parameters. </bold>We show the response of the system to two levels of perturbations of size 7% and 9%. (A) The linearized perturbed system superimposed on the approximate nominal limit cycle obtained using the harmonic balance method. (B) The response of the non-linear system. For the perturbation of size 7% the linearized system is stable and so we see the responses settle into a stable limit cycle. For 9%, the linearized system is no longer stable, so that the response of the linear system increases unboundedly, as the trajectory moves away from the nominal equilibrium. In the non-linear response we see this manifested as a transition to a stable steady state.</p></caption><graphic xlink:href="1471-2105-3-38-7"/></fig><p>This example illustrates how a robustness analysis of the linearized system can be used to deduce the robustness of the original non-linear system, as it shows that when the linearized system is unstable, the desired behaviour of the non-linear system will no longer be present. This example also points out the fact that the upper bound &#x003bc;<sup><italic>upper </italic></sup>&#x02245; 8.3% is not overly conservative for this system as we were able to produce a destabilizing perturbation of size 9%.</p><p>Finally, we note that multiparametric robustness analysis considered here is based on local properties of the dynamical system, since we are evaluating the robustness of the linearized model. Extensions to the non-linear model are the subject of active investigation [<xref ref-type="bibr" rid="B27">27</xref>].</p><p>However, it is by combining the robustness analysis of both single and multiple parameters, we can obtain a more thorough understanding of the region of stability of the periodic solution in the high dimensional parameter space and use this to improve upon the model. In this particular example, we find that the system's robustness is governed by several "robustness limiting" parameters, <italic>k</italic><sub>2</sub>, <italic>k</italic><sub>4</sub>, <italic>k</italic><sub>10 </sub>and <italic>k</italic><sub>14</sub>.</p></sec><sec><title>Conclusions</title><p>Determining the robustness of mathematical models of biological systems is important for several reasons. First, there is growing evidence that many aspects of the networks being modelled have evolved in such a way so that they are robust as this allows them to tolerate natural variations in the environment. Thus, faithful models should replicate this robustness. Second, robustness of the models provide a means of validating model quality since the performance of the models should not rely on precisely tuned parameter values that are impossible &#x02013; or at best &#x02013; difficult to measure exactly.</p><p>In this paper, we illustrated the use of two tools developed in dynamical systems theory and control engineering to assess robustness quantitatively. For an example, we considered an oscillatory molecular network model due to Laub and Loomis that aims at describing oscillatory behaviour in cAMP signalling observed in the social amoeba <italic>D. discoideum. </italic>This behaviour appears as a stable limit cycle of the equations describing the model. We have evaluated the degree to which this limit cycle is robust to variations in all the system parameters.</p><p>The robustness of the oscillatory behaviour to single parameter variations was quantified using bifurcation analysis. Using the bifurcation analysis software tool AUTO we determined that single parameter changes as small as 20% from the nominal value can cause the limit cycle to disappear and a stable equilibrium to appear. In addition to the stability robustness, AUTO is also able to evaluate the sensitivity of the amplitude of the oscillation to these parameter changes.</p><p>To investigate the robustness of the model to simultaneous changes in parameter values, the structured singular value (SSV) analysis tool was used. Once the system was in the correct framework for SSV analysis, we were able to determine that the system can only tolerate very small changes in the parameter values &#x02013; in the order of 8% &#x02013; if we allow these parameters to vary with time arbitrarily slowly.</p><p>Finally, it is important to note that to understand completely the robustness properties of a model, it is appropriate to combine single and multiple parameter sensitivity analyses.</p></sec><sec><title>Authors' contributions</title><p>LM carried out the computational studies and analysis. PAI conceived of the study and participated in its design and coordination. All authors read and approved the final manuscript.</p></sec></body><back><sec><title>Acknowledgements</title><p>We thank J. Krishnan and W.J. Rugh for useful comments on the manuscript. This work was supported in part by the Whitaker Foundation and the National Science Foundation's Biocomplexity program, through grant number DMS-0083500.</p></sec><ref-list><ref id="B1"><mixed-citation publication-type="journal"><name><surname>Barkai</surname><given-names>N</given-names></name><name><surname>Leibler</surname><given-names>S</given-names></name><article-title>Robustness in simple biochemical networks.</article-title><source>Nature</source><year>1997</year><volume>387</volume><fpage>913</fpage><lpage>917</lpage><pub-id pub-id-type="doi">10.1038/43199</pub-id><pub-id pub-id-type="pmid">9202124</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><name><surname>Alon</surname><given-names>U</given-names></name><name><surname>Surette</surname><given-names>MG</given-names></name><name><surname>Barkai</surname><given-names>N</given-names></name><name><surname>Leibler</surname><given-names>S</given-names></name><article-title>Robustness in bacterial chemotaxis.</article-title><source>Nature</source><year>1999</year><volume>397</volume><fpage>168</fpage><lpage>171</lpage><pub-id pub-id-type="doi">10.1038/16483</pub-id><pub-id pub-id-type="pmid">9923680</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><name><surname>von Dassow</surname><given-names>G</given-names></name><name><surname>Meir</surname><given-names>E</given-names></name><name><surname>Munro</surname><given-names>EM</given-names></name><name><surname>Odell</surname><given-names>GM</given-names></name><article-title>The segment polarity network is a robust developmental module.</article-title><source>Nature</source><year>2000</year><volume>406</volume><fpage>188</fpage><lpage>192</lpage><pub-id pub-id-type="doi">10.1038/35018085</pub-id><pub-id pub-id-type="pmid">10910359</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><name><surname>Meir</surname><given-names>E</given-names></name><name><surname>von Dassow</surname><given-names>G</given-names></name><name><surname>Munro</surname><given-names>E</given-names></name><name><surname>Odell</surname><given-names>GM</given-names></name><article-title>Robustness, flexibility, and the role of lateral inhibition in the neurogenic network.</article-title><source>Curr Biol</source><year>2002</year><volume>12</volume><fpage>778</fpage><lpage>786</lpage><pub-id pub-id-type="doi">10.1016/S0960-9822(02)00839-4</pub-id><pub-id pub-id-type="pmid">12015114</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><name><surname>Savageau</surname><given-names>MA</given-names></name><article-title>Parameter sensitivity as a criterion for evaluating and comparing the performance of biochemical systems.</article-title><source>Nature</source><year>1971</year><volume>229</volume><fpage>542</fpage><lpage>544</lpage><pub-id pub-id-type="pmid">4925348</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><name><surname>Morohashi</surname><given-names>M</given-names></name><name><surname>Winn</surname><given-names>AE</given-names></name><name><surname>Borisuk</surname><given-names>MT</given-names></name><name><surname>Bolouri</surname><given-names>H</given-names></name><name><surname>Doyle</surname><given-names>J</given-names></name><name><surname>Kitano</surname><given-names>H</given-names></name><article-title>Robustness as a measure of plausibility in models of biochemical networks.</article-title><source>J Theor Biol</source><year>2002</year><volume>216</volume><fpage>19</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1006/jtbi.2002.2537</pub-id><pub-id pub-id-type="pmid">12076125</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><name><surname>Alves</surname><given-names>R</given-names></name><name><surname>Savageau</surname><given-names>MA</given-names></name><article-title>Extending the method of mathematically controlled comparison to include numerical comparisons.</article-title><source>Bioinformatics</source><year>2000</year><volume>16</volume><fpage>786</fpage><lpage>798</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/16.9.786</pub-id><pub-id pub-id-type="pmid">11108701</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><name><surname>Laub</surname><given-names>MT</given-names></name><name><surname>Loomis</surname><given-names>WF</given-names></name><article-title>A molecular network that produces spontaneous oscillations in excitable cells of <italic>Dictyostelium</italic>.</article-title><source>Mol Biol Cell</source><year>1998</year><volume>9</volume><fpage>3521</fpage><lpage>3532</lpage><pub-id pub-id-type="pmid">9843585</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="book"><name><surname>Liu</surname><given-names>JS</given-names></name><source>Monte Carlo strategies in scientific computing</source><year>2001</year><publisher-name>New York: Springer</publisher-name></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="book"><name><surname>Zhou</surname><given-names>K</given-names></name><name><surname>Doyle</surname><given-names>JC</given-names></name><name><surname>Glover</surname><given-names>K</given-names></name><source>Robust and optimal control</source><year>1996</year><publisher-name>Englewood Cliffs, NJ: Prentice-Hall</publisher-name></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="book"><name><surname>Strogatz</surname><given-names>SH</given-names></name><source>Nonlinear dynamics and chaos</source><year>1994</year><publisher-name>Cambridge: Perseus</publisher-name></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><name><surname>Borisuk</surname><given-names>MT</given-names></name><name><surname>Tyson</surname><given-names>JJ</given-names></name><article-title>Bifurcation analysis of a model of mitotic control in frog eggs.</article-title><source>Journal of Theoretical Biology</source><year>1998</year><volume>195</volume><fpage>69</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1006/jtbi.1998.0781</pub-id><pub-id pub-id-type="pmid">9802951</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><name><surname>Enns-Ruttan</surname><given-names>JS</given-names></name><name><surname>Miura</surname><given-names>RM</given-names></name><article-title>Spontaneous secondary spiking in excitable cells.</article-title><source>Journal of Theoretical Biology</source><year>2000</year><volume>205</volume><fpage>181</fpage><lpage>199</lpage><pub-id pub-id-type="doi">10.1006/jtbi.2000.2056</pub-id><pub-id pub-id-type="pmid">10873431</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="book"><name><surname>Doedel</surname><given-names>E</given-names></name><name><surname>Champneys</surname><given-names>AR</given-names></name><name><surname>Fairgrieve</surname><given-names>TF</given-names></name><name><surname>Kuznetsov</surname><given-names>YA</given-names></name><name><surname>Sandstede</surname><given-names>B</given-names></name><name><surname>Wang</surname><given-names>XJ</given-names></name><source>AUTO 97: Continuation and bifurcation software for ordinary differential equations</source><year>1997</year><publisher-name>Montr&#x000e9;al, Canada: Publisher</publisher-name></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><name><surname>Doyle</surname><given-names>J</given-names></name><article-title>Analysis of feedback-systems with structured uncertainties.</article-title><source>IEE Proceedings-D Control Theory and Applications</source><year>1982</year><volume>129</volume><fpage>242</fpage><lpage>250</lpage></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><name><surname>Zames</surname><given-names>G</given-names></name><article-title>On input-output stability of time-varying nonlinear feedback systems, I: Conditions derived using concepts of loop gain conicity and positivity.</article-title><source>IEEE Transactions on Automatic Control</source><year>1966</year><volume>AC11</volume><fpage>228</fpage><lpage>238</lpage></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="book"><name><surname>Khalil</surname><given-names>HK</given-names></name><source>Nonlinear systems</source><year>2002</year><edition>3</edition><publisher-name>Englewood Cliffs, NJ: Prentice Hall</publisher-name></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="book"><name><surname>Chen</surname><given-names>T</given-names></name><name><surname>Francis</surname><given-names>BA</given-names></name><source>Optimal sampled-data control systems</source><year>1995</year><publisher-name>London: Springer-Verlag</publisher-name></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="book"><name><surname>Rugh</surname><given-names>WJ</given-names></name><source>Linear system theory</source><year>1996</year><publisher-name>Englewood Cliffs, NJ: Prentice-Hall</publisher-name></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><name><surname>Qiu</surname><given-names>L</given-names></name><name><surname>Bernhardsson</surname><given-names>B</given-names></name><name><surname>Rantzer</surname><given-names>A</given-names></name><name><surname>Davison</surname><given-names>EJ</given-names></name><name><surname>Young</surname><given-names>PM</given-names></name><name><surname>Doyle</surname><given-names>JC</given-names></name><article-title>A formula for computation of the real stability radius.</article-title><source>Automatica</source><year>1995</year><volume>31</volume><fpage>879</fpage><lpage>890</lpage><pub-id pub-id-type="doi">10.1016/0005-1098(95)00024-Q</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><name><surname>Braatz</surname><given-names>RP</given-names></name><name><surname>Young</surname><given-names>PM</given-names></name><name><surname>Doyle</surname><given-names>JC</given-names></name><name><surname>Morari</surname><given-names>M</given-names></name><article-title>Computational-complexity of &#x003bc;-calculation.</article-title><source>IEEE Transactions on Automatic Control</source><year>1994</year><volume>39</volume><fpage>1000</fpage><lpage>1002</lpage><pub-id pub-id-type="doi">10.1109/9.284879</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><name><surname>Balas</surname><given-names>GJ</given-names></name><name><surname>Doyle</surname><given-names>JC</given-names></name><name><surname>Glover</surname><given-names>K</given-names></name><name><surname>Packard</surname><given-names>A</given-names></name><name><surname>Smith</surname><given-names>R</given-names></name><article-title>&#x003bc;-analysis and synthesis toolbox (Mu-Tools).</article-title><source>Automatica</source><year>1994</year><volume>30</volume><fpage>733</fpage><lpage>735</lpage><pub-id pub-id-type="doi">10.1016/0005-1098(94)90164-3</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><name><surname>Gerisch</surname><given-names>G</given-names></name><name><surname>Wick</surname><given-names>U</given-names></name><article-title>Intracellular oscillations and release of cyclic AMP from <italic>Dictyostelium </italic>cells.</article-title><source>Biochem Biophys Res Commun</source><year>1975</year><volume>65</volume><fpage>364</fpage><lpage>370</lpage><pub-id pub-id-type="pmid">167769</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><name><surname>Freeman</surname><given-names>M</given-names></name><article-title>Feedback control of intercellular signalling in development.</article-title><source>Nature</source><year>2000</year><volume>408</volume><fpage>313</fpage><lpage>319</lpage><pub-id pub-id-type="doi">10.1038/35042500</pub-id><pub-id pub-id-type="pmid">11099031</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="book"><name><surname>Haefner</surname><given-names>JW</given-names></name><source>Modeling biological systems: Principles and applications</source><year>1996</year><publisher-name>New York: Chapman and Hall</publisher-name></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><name><surname>J&#x000f6;nsson</surname><given-names>U</given-names></name><name><surname>Rantzer</surname><given-names>A</given-names></name><article-title>Systems with uncertain parameters &#x02013; time-variations with bounded derivatives.</article-title><source>Internat J Robust Nonlinear Control</source><year>1996</year><volume>6</volume><fpage>969</fpage><lpage>982</lpage><pub-id pub-id-type="doi">10.1002/(SICI)1099-1239(199611)6:9/10&#x0003c;969::AID-RNC262&#x0003e;3.3.CO;2-R</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="book"><name><surname>Parrilo</surname><given-names>PA</given-names></name><source>Structured semidefinite programs and semialgebraic geometry methods in robustness and optimization</source><year>2000</year><publisher-name>Pasadena, CA: California Institute of Technology</publisher-name></mixed-citation></ref></ref-list></back></article>